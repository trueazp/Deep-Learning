{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pertemuan04-PDL-H071191035.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLhmp35geRVj"
      },
      "source": [
        "<H1><b>Pertemuan 4 - Convolutional Neural Network (CNN</b></H1>\n",
        "\n",
        "<H3>Nama : Akmal Zuhdy Prasetya</H3>\n",
        "<H3>NIM  : H071191035</H3>\n",
        "<H5>Berdasarkan: <a>http://d2l.ai/chapter_convolutional-neural-networks/index.html<a><H5>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eligible-speaker"
      },
      "source": [
        "# **2. Convolutions for Images**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "secure-adolescent"
      },
      "source": [
        "## **2.1 The Cross-Correlation Operation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cutting-bacteria"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "passive-honolulu"
      },
      "outputs": [],
      "source": [
        "def corr2d(X, K):\n",
        "    h, w = K.shape\n",
        "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
        "    for i in range(Y.shape[0]):\n",
        "        for j in range(Y.shape[1]):\n",
        "            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()\n",
        "    return Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pending-edwards",
        "outputId": "a1f18ac9-7b74-4874-9cbd-c690a8d2e973",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[19., 25.],\n",
              "        [37., 43.]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
        "K = torch.tensor([[0.0, 1.0], [2.0, 3.0]])\n",
        "corr2d(X, K)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "charitable-sight"
      },
      "source": [
        "## **2.2 Convolutional Layers**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "transsexual-samoa"
      },
      "outputs": [],
      "source": [
        "class Conv2D(nn.Module):\n",
        "    def __init__(self, kernel_size):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.rand(kernel_size))\n",
        "        self.bias = nn.Parameter(torch.zeros(1))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return corr2d(x, self.weight) + self.bias\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sweet-mortgage"
      },
      "source": [
        "## **2.3 Object Edge Detection in Images**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "diagnostic-organizer",
        "outputId": "8d8bd463-48bf-40ac-922a-86c9bbb43288",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "        [1., 1., 0., 0., 0., 0., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "X = torch.ones((6, 8))\n",
        "X[:, 2:6] = 0\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "thirty-waters",
        "outputId": "b67ede04-648e-4235-f9dc-27142bf7b529",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1., -1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "K = torch.tensor([[1.0, -1.0]])\n",
        "K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "going-blade",
        "outputId": "b6e878c0-656c-4d69-ebb8-b71a13c7b8ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
              "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
              "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
              "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
              "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
              "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "Y = corr2d(X, K)\n",
        "Y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "average-formula"
      },
      "source": [
        "**Transposed image**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "static-present",
        "outputId": "8a53feb4-dbae-4b6f-864a-80f05f8c036c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "corr2d(X.t(), K)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "precious-demonstration"
      },
      "source": [
        "## **2.4 Learning a Kernel**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "satisfactory-nirvana",
        "outputId": "c193cf74-101e-4f0d-e54b-0aa23670a0ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2, loss 14.701\n",
            "epoch 4, loss 4.598\n",
            "epoch 6, loss 1.644\n",
            "epoch 8, loss 0.633\n",
            "epoch 10, loss 0.253\n"
          ]
        }
      ],
      "source": [
        "conv2d = nn.Conv2d(1, 1, kernel_size=(1, 2), bias=False)\n",
        "\n",
        "#(example, channel, height, width)\n",
        "X = X.reshape((1, 1, 6, 8))\n",
        "Y = Y.reshape((1, 1, 6, 7))\n",
        "lr = 3e-2\n",
        "\n",
        "for i in range(10):\n",
        "    Y_hat = conv2d(X)\n",
        "    l = (Y_hat - Y) ** 2\n",
        "    conv2d.zero_grad()\n",
        "    l.sum().backward()\n",
        "\n",
        "    conv2d.weight.data[:] -= lr * conv2d.weight.grad\n",
        "    if (i + 1) % 2 == 0:\n",
        "        print(f'epoch {i + 1}, loss {l.sum():.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "conservative-correction",
        "outputId": "076fe185-420a-4017-c2ba-b2410fcb2f81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.9359, -1.0388]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "conv2d.weight.data.reshape((1, 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "personalized-dubai"
      },
      "source": [
        "# **3 Padding and Stride**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tracked-recording"
      },
      "source": [
        "## **3.1 Padding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "professional-onion",
        "outputId": "00774ab0-7805-4cd4-aa75-65b8f6054893",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "def comp_conv2d(conv2d, X):\n",
        "    X = X.reshape((1, 1) + X.shape)\n",
        "    Y = conv2d(X)\n",
        "    return Y.reshape(Y.shape[2:])\n",
        "conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1)\n",
        "X = torch.rand(size=(8, 8))\n",
        "comp_conv2d(conv2d, X).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "arbitrary-silicon",
        "outputId": "1de5d516-d06b-4098-995d-b2c30e39da03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "conv2d = nn.Conv2d(1, 1, kernel_size=(5, 3), padding=(3, 1))\n",
        "comp_conv2d(conv2d, X).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fossil-cover"
      },
      "source": [
        "## **3.2 Stride**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "complimentary-breathing",
        "outputId": "d6dfe3d7-e801-4eab-9eb0-09869dd8cd2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1, stride=2)\n",
        "comp_conv2d(conv2d, X).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "trained-punishment",
        "outputId": "649ddfca-5170-46d5-ee46-d772f93e26c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "dominant-astronomy",
        "outputId": "1b904035-c900-49d6-8e37-fd9ebd327f52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "conv2d = nn.Conv2d(1, 1, kernel_size=(3, 5), padding=(0, 1), stride=(3, 4))\n",
        "comp_conv2d(conv2d, X).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pleasant-french"
      },
      "source": [
        "# **4. Miltiple Input and Multiple Output Channels**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chinese-infection"
      },
      "source": [
        "## **4.1 Multiple Input Channels**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "handmade-insight"
      },
      "outputs": [],
      "source": [
        "def corr2d_multi_in(X, K):\n",
        "    \n",
        "    return sum(corr2d(x, k) for x, k in zip(X, K))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "residential-amplifier",
        "outputId": "a4d39a58-92c0-428a-a916-1733ae40fb17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 56.,  72.],\n",
              "        [104., 120.]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],\n",
        "               [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])\n",
        "K = torch.tensor([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])\n",
        "corr2d_multi_in(X, K)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nearby-vector"
      },
      "source": [
        "## **4.2 Multiple Output Channels**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "identified-yellow"
      },
      "outputs": [],
      "source": [
        "def corr2d_multi_in_out(X, K):\n",
        "    return torch.stack([corr2d_multi_in(X, k) for k in K], 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "comparative-project",
        "outputId": "1af6d5b9-32e7-4b83-9d35-a50d5df52ec5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "K = torch.stack((K, K + 1, K+2), 0)\n",
        "K.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "modified-continent",
        "outputId": "c3abcb6b-6db0-4000-81f4-356f7ef8cd56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "involved-strain",
        "outputId": "df4bfc86-207d-4f22-f90a-e22e2fb1c8a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "corr2d_multi_in_out(X, K).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reserved-timber"
      },
      "source": [
        "## **4.3 1x1 Convolutional Layer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "global-carry"
      },
      "outputs": [],
      "source": [
        "def corr2d_multi_in_out_1x1(X, K):\n",
        "    c_i, h, w = X.shape\n",
        "    c_o = K.shape[0]\n",
        "    X = X.reshape((c_i, h * w))\n",
        "    K = K.reshape((c_o, c_i))\n",
        "    \n",
        "    Y = torch.matmul(K, X)\n",
        "    return Y.reshape((c_o, h, w))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "delayed-dominican"
      },
      "outputs": [],
      "source": [
        "X = torch.normal(0, 1, (3, 3, 3))\n",
        "K = torch.normal(0, 1, (2, 3, 1, 1))\n",
        "\n",
        "Y1 = corr2d_multi_in_out_1x1(X, K)\n",
        "Y2 = corr2d_multi_in_out(X, K)\n",
        "assert float(torch.abs(Y1 - Y2).sum()) < 1e-6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "capital-humidity"
      },
      "source": [
        "# **5. Pooling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "invalid-wellington"
      },
      "source": [
        "## **5.1 Maximum Pooling and Average Pooling**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "remarkable-franklin"
      },
      "outputs": [],
      "source": [
        "def pool2d(X, pool_size, mode='max'):\n",
        "    p_h, p_w = pool_size\n",
        "    Y = torch.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1))\n",
        "    for i in range(Y.shape[0]):\n",
        "        for j in range(Y.shape[1]):\n",
        "            if mode == 'max':\n",
        "                Y[i, j] = X[i: i + p_h, j: j + p_w].max()\n",
        "            elif mode == 'avg':\n",
        "                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()\n",
        "    return Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "presidential-reward",
        "outputId": "1b52843d-8e32-4118-9e8b-1e30ceb1a21d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4., 5.],\n",
              "        [7., 8.]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
        "pool2d(X, (2, 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "complimentary-talent",
        "outputId": "24bd38fe-3c48-4cb3-b8a4-b9088b467f32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 3.],\n",
              "        [5., 6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "pool2d(X, (2, 2), 'avg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "hairy-addiction",
        "outputId": "d419399f-1b3d-464e-9114-0080bc9d5d8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 0.,  1.,  2.,  3.],\n",
              "          [ 4.,  5.,  6.,  7.],\n",
              "          [ 8.,  9., 10., 11.],\n",
              "          [12., 13., 14., 15.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "X = torch.arange(16, dtype=torch.float32).reshape((1, 1, 4, 4))\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "dietary-clinton",
        "outputId": "d43c1aa1-ecff-43dd-9188-2dbf103b8435",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 5.,  7.],\n",
              "          [13., 15.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
        "pool2d(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "fresh-binding",
        "outputId": "dd168b8d-d118-4e9c-de82-0fae43454080",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 5.,  7.],\n",
              "          [13., 15.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "pool2d = nn.MaxPool2d((2, 3), stride=(2, 3), padding=(0, 1))\n",
        "pool2d(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raised-record"
      },
      "source": [
        "## **5.3 Multiple Channels**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "authentic-howard",
        "outputId": "2754d662-b6a6-43e9-8cf9-08f89d529677",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 0.,  1.,  2.,  3.],\n",
              "          [ 4.,  5.,  6.,  7.],\n",
              "          [ 8.,  9., 10., 11.],\n",
              "          [12., 13., 14., 15.]],\n",
              "\n",
              "         [[ 1.,  2.,  3.,  4.],\n",
              "          [ 5.,  6.,  7.,  8.],\n",
              "          [ 9., 10., 11., 12.],\n",
              "          [13., 14., 15., 16.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "X = torch.cat((X, X + 1), 1)\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "statewide-dynamics",
        "outputId": "944d3d97-08e9-4c12-d1ff-a5225db44426",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 5.,  7.],\n",
              "          [13., 15.]],\n",
              "\n",
              "         [[ 6.,  8.],\n",
              "          [14., 16.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
        "pool2d(X)"
      ]
    }
  ]
}