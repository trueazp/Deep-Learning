{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pertemuan03-PDL-H071191035.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLhmp35geRVj"
      },
      "source": [
        "<H1><b>Pertemuan 3 - Deep Learning Computation</b></H1>\n",
        "\n",
        "<H3>Nama : Akmal Zuhdy Prasetya</H3>\n",
        "<H3>NIM  : H071191035</H3>\n",
        "<H5>Berdasarkan: <a>http://d2l.ai/chapter_deep-learning-computation/index.html<a><H5>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Library**"
      ],
      "metadata": {
        "id": "1j0waZABI1k5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "universal-prevention"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "second-swaziland"
      },
      "source": [
        "# **1. Layers and Blocks**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piano-measure"
      },
      "source": [
        "**MLP**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "shared-samoa",
        "outputId": "67edffe5-bbe8-421a-fd45-35b7169f0513",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0298, -0.3064, -0.1718,  0.1286,  0.0560, -0.3811,  0.0778,  0.1881,\n",
              "          0.0587, -0.0960],\n",
              "        [-0.0164, -0.2427, -0.1251,  0.1777, -0.0421, -0.2020,  0.0061,  0.0499,\n",
              "         -0.0118, -0.0924]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "net = nn.Sequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
        "\n",
        "X = torch.rand(2, 20)\n",
        "net(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ambient-status"
      },
      "source": [
        "## **1.1 A Custom Block**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "aggressive-mouse"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.hidden = nn.Linear(20, 256)\n",
        "        self.out = nn.Linear(256, 10)\n",
        "    \n",
        "    def forward(self, X):\n",
        "        return self.out(F.relu(self.hidden(X)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "rental-conservative",
        "outputId": "09cf21ce-14dd-4276-e57b-801cab4d953b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0721,  0.0100, -0.3043,  0.1977, -0.0716, -0.0512,  0.1893, -0.2582,\n",
              "          0.0129,  0.2804],\n",
              "        [ 0.2241,  0.1323, -0.1806,  0.0335, -0.1396,  0.0372,  0.0698, -0.1285,\n",
              "          0.0034,  0.2503]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "net = MLP()\n",
        "net(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "happy-inspection"
      },
      "source": [
        "## **1.2 The Sequential Block**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "israeli-dover"
      },
      "outputs": [],
      "source": [
        "class MySequential(nn.Module):\n",
        "    def __init__(self, *args):\n",
        "        super().__init__()\n",
        "        for idx, module in enumerate(args):\n",
        "            self._modules[str(idx)] = module\n",
        "    \n",
        "    def forward(self, X):\n",
        "        for block in self._modules.values():\n",
        "            X = block(X)\n",
        "        return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "neural-patrol",
        "outputId": "afd3928c-320d-4f56-8c61-6f78d01dd533",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0737,  0.1467, -0.1244,  0.3718, -0.1908, -0.2584, -0.0944, -0.2627,\n",
              "         -0.0133,  0.0866],\n",
              "        [-0.0418,  0.0356, -0.1332,  0.4029, -0.3072, -0.2015, -0.0522, -0.1243,\n",
              "          0.1106,  0.2236]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "net = MySequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
        "net(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "local-carrier"
      },
      "source": [
        "## **1.3 Executing Code in the Forward Propagation Function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "labeled-capability"
      },
      "outputs": [],
      "source": [
        "class FixedHiddenMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.rand_weight = torch.rand((20, 20), requires_grad=False)\n",
        "        self.linear = nn.Linear(20, 20)\n",
        "        \n",
        "    def forward(self, X):\n",
        "        X = self.linear(X)\n",
        "        X = F.relu(torch.mm(X, self.rand_weight) + 1)\n",
        "        X = self.linear(X)\n",
        "        while X.abs().sum() > 1:\n",
        "            X /=2\n",
        "        return X.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "furnished-proposal",
        "outputId": "0f36664a-85d3-47ef-c12f-3e09c255be52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0016, grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "net = FixedHiddenMLP()\n",
        "net(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "minute-mississippi",
        "outputId": "43a649f6-dd21-431f-a6ff-ff853bc54607",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.1690, grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "class NestMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(nn.Linear(20, 64), nn.ReLU(),\n",
        "                                 nn.Linear(64, 32), nn. ReLU())\n",
        "        self.linear = nn.Linear(32, 16)\n",
        "    \n",
        "    def forward(self, X):\n",
        "        return self.linear(self.net(X))\n",
        "\n",
        "chimera = nn.Sequential(NestMLP(), nn.Linear(16, 20), FixedHiddenMLP())\n",
        "chimera(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "renewable-booking"
      },
      "source": [
        "# **2. Parameter Management**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "optimum-accounting"
      },
      "source": [
        "## **2.1 Parameter Access**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "quality-bathroom",
        "outputId": "3e1194f6-1045-4b16-92ad-ebeb112c6122",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1747],\n",
              "        [-0.1797]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 1))\n",
        "X = torch.rand(size=(2, 4))\n",
        "net(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "weird-springfield",
        "outputId": "8a88478e-962f-4101-cb55-9a95ed8b3c3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('weight', tensor([[-0.0712, -0.0271, -0.0533, -0.1187, -0.0261,  0.2001,  0.0247,  0.0779]])), ('bias', tensor([-0.0897]))])\n"
          ]
        }
      ],
      "source": [
        "print(net[2].state_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "pressed-german",
        "outputId": "2cb84a63-e1b7-4efc-b4e0-abe4904b6a15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.nn.parameter.Parameter'>\n",
            "Parameter containing:\n",
            "tensor([-0.0897], requires_grad=True)\n",
            "tensor([-0.0897])\n"
          ]
        }
      ],
      "source": [
        "print(type(net[2].bias))\n",
        "print(net[2].bias)\n",
        "print(net[2].bias.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "duplicate-contact",
        "outputId": "21117b71-87ff-4ac3-e6f5-e8df5b22b3ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "net[2].weight.grad == None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "continental-chassis",
        "outputId": "28a42ba1-f1b2-4eb7-ebfa-ccdb9e28e4c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('weight', torch.Size([8, 4])) ('bias', torch.Size([8]))\n",
            "('0.weight', torch.Size([8, 4])) ('0.bias', torch.Size([8])) ('2.weight', torch.Size([1, 8])) ('2.bias', torch.Size([1]))\n"
          ]
        }
      ],
      "source": [
        "print(*[(name, param.shape) for name, param in net[0].named_parameters()])\n",
        "print(*[(name, param.shape) for name, param in net.named_parameters()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "employed-arbor",
        "outputId": "4dd78411-daa3-4592-cbe4-a923794279f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.0897])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "net.state_dict()['2.bias'].data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "above-discipline",
        "outputId": "86c44afb-f4f6-4437-acc2-d793ecf3f001",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2344],\n",
              "        [-0.2344]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "def block1():\n",
        "    return nn.Sequential(nn.Linear(4, 8), nn.ReLU(),\n",
        "                         nn.Linear(8, 4), nn.ReLU())\n",
        "\n",
        "def block2():\n",
        "    net = nn.Sequential()\n",
        "    for i in range(4):\n",
        "        net.add_module(f'block {i}', block1())\n",
        "    return net\n",
        "\n",
        "rgnet = nn.Sequential(block2(), nn.Linear(4, 1))\n",
        "rgnet(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "linear-master",
        "outputId": "612bbaf6-4cb1-44d7-9ed9-d53b4589afff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Sequential(\n",
            "    (block 0): Sequential(\n",
            "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (block 1): Sequential(\n",
            "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (block 2): Sequential(\n",
            "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (block 3): Sequential(\n",
            "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
            "      (3): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (1): Linear(in_features=4, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(rgnet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "southwest-minister",
        "outputId": "c3431cf6-38fc-41a2-9569-e1af808fad33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.1841, -0.4663,  0.1562, -0.0297,  0.4831, -0.0442, -0.2568, -0.2047])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "rgnet[0][1][0].bias.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lonely-tunnel"
      },
      "source": [
        "## **2.2 Parameter Initialization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "covered-software"
      },
      "source": [
        "### **2.2.1 Built-in Initialization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "later-rachel",
        "outputId": "e7412944-f44f-4b04-df40-104e04647b30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 0.0165,  0.0054, -0.0027,  0.0200]), tensor(0.))"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "def init_normal(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        nn.init.normal_(m.weight, mean=0, std=0.01)\n",
        "        nn.init.zeros_(m.bias)\n",
        "net.apply(init_normal)\n",
        "net[0].weight.data[0], net[0].bias.data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "regulation-poison",
        "outputId": "dc0a195b-3a15-4076-f45f-89dc234a6699",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 1., 1., 1.]), tensor(0.))"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "def init_constant(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        nn.init.constant_(m.weight, 1)\n",
        "        nn.init.zeros_(m.bias)\n",
        "net.apply(init_constant)\n",
        "net[0].weight.data[0], net[0].bias.data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "reflected-corner",
        "outputId": "bfddc2e0-3a03-4715-841c-58d94a684b24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.1352, -0.6523, -0.1155, -0.4591])\n",
            "tensor([[42., 42., 42., 42., 42., 42., 42., 42.]])\n"
          ]
        }
      ],
      "source": [
        "def xavier(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        nn.init.xavier_uniform_(m.weight)\n",
        "def init_42(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        nn.init.constant_(m.weight, 42)\n",
        "        \n",
        "net[0].apply(xavier)\n",
        "net[2].apply(init_42)\n",
        "print(net[0].weight.data[0])\n",
        "print(net[2].weight.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "natural-barrel"
      },
      "source": [
        "### **2.2.2 Custom Initialization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "sacred-temple",
        "outputId": "607830d2-c1f6-4644-9772-be60fef356b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Init weight torch.Size([8, 4])\n",
            "Init weight torch.Size([1, 8])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 6.9860,  0.0000,  0.0000, -7.2898],\n",
              "        [ 9.6665,  0.0000,  8.1232,  7.6009]], grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "def my_init(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        print(\"Init\", *[(name, param.shape) for name, param in m.named_parameters()][0])\n",
        "        nn.init.uniform_(m.weight, -10, 10)\n",
        "        m.weight.data *= m.weight.data.abs() >=5\n",
        "        \n",
        "net.apply(my_init)\n",
        "net[0].weight[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "legal-burns",
        "outputId": "961d8851-082b-45ae-afff-1f209fc23504",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([42.0000,  1.0000,  1.0000, -6.2898])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "net[0].weight.data[:] += 1\n",
        "net[0].weight.data[0, 0] = 42\n",
        "net[0].weight.data[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "occupied-smell"
      },
      "source": [
        "### **2.2.3 Tied Parameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "perfect-conviction",
        "outputId": "fd5da2f9-4868-43b8-9008-0799d9753b71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([True, True, True, True, True, True, True, True])\n",
            "tensor([True, True, True, True, True, True, True, True])\n"
          ]
        }
      ],
      "source": [
        "shared = nn.Linear(8, 8)\n",
        "net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(),\n",
        "                    shared, nn.ReLU(),\n",
        "                    shared, nn.ReLU(),\n",
        "                    nn.Linear(8, 1))\n",
        "net(X)\n",
        "\n",
        "print(net[2].weight.data[0] == net[4].weight.data[0])\n",
        "net[2].weight.data[0, 0] = 100\n",
        "print(net[2].weight.data[0] == net[4].weight.data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rubber-seeking"
      },
      "source": [
        "# **4. Custom Layers**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dietary-times"
      },
      "source": [
        "## **4.1 Layers without Parameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "declared-sherman"
      },
      "outputs": [],
      "source": [
        "class CenteredLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "    def forward(self, X):\n",
        "        return X - X.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "efficient-heaven",
        "outputId": "ee9fa914-e929-4d57-b90e-2546cc768a00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-2., -1.,  0.,  1.,  2.])"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        "layer = CenteredLayer()\n",
        "layer(torch.FloatTensor([1, 2, 3, 4, 5]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "spoken-inclusion"
      },
      "outputs": [],
      "source": [
        "net = nn.Sequential(nn.Linear(8, 128), CenteredLayer())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "widespread-attendance",
        "outputId": "d1c666ca-a6a8-4942-da92-98adba7427a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.7253e-09, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "Y =net(torch.rand(4, 8))\n",
        "Y.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "academic-housing"
      },
      "source": [
        "## **4.2 Layers with Parameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "neural-albany"
      },
      "outputs": [],
      "source": [
        "class MyLinear(nn.Module):\n",
        "    def __init__(self, in_units, units):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.randn(in_units, units))\n",
        "        self.bias = nn.Parameter(torch.randn(units,))\n",
        "        \n",
        "    def forward(self, X):\n",
        "        linear = torch.matmul(X, self.weight.data) + self.bias.data\n",
        "        return F.relu(linear)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "unknown-isaac",
        "outputId": "0b013e24-7113-42da-a119-9c717828e633",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.7676, -0.0545, -0.5944],\n",
              "        [-0.9176,  0.0344,  1.6060],\n",
              "        [ 0.5840,  0.5776,  0.7196],\n",
              "        [-0.1227,  0.2799, -1.1174],\n",
              "        [ 1.6724, -2.6224,  0.9776]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "source": [
        "linear = MyLinear(5, 3)\n",
        "linear.weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "nonprofit-relative",
        "outputId": "f7bf2916-48e0-4a97-d7f0-727c2da909ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3.1517, 0.0000, 1.2425],\n",
              "        [2.6486, 0.0000, 2.1800]])"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "linear(torch.rand(2, 5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "distant-hours",
        "outputId": "5fd472fa-1517-4c8b-85f5-159650b6696f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.],\n",
              "        [0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ],
      "source": [
        "net = nn.Sequential(MyLinear(64, 8), MyLinear(8, 1))\n",
        "net(torch.rand(2, 64))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "undefined-protest"
      },
      "source": [
        "# **5. File I/O**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quality-finish"
      },
      "source": [
        "## **5.1 Loading and Saving Tensors**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "grateful-battery"
      },
      "outputs": [],
      "source": [
        "x = torch.arange(4)\n",
        "torch.save(x, 'x-file')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "burning-motor",
        "outputId": "9cd1b0e5-99c4-4ee9-f43f-fb1dd2f4990a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ],
      "source": [
        "x2 = torch.load('x-file')\n",
        "x2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "buried-france",
        "outputId": "e8bbef16-f9b6-4380-cd73-8852cca87fb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0, 1, 2, 3]), tensor([0., 0., 0., 0.]))"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "y = torch.zeros(4)\n",
        "torch.save([x, y], 'x-files')\n",
        "x2, y2 = torch.load('x-files')\n",
        "(x2, y2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "decimal-index",
        "outputId": "c4844a02-7023-41a2-ff0b-9a6fec2da3d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'x': tensor([0, 1, 2, 3]), 'y': tensor([0., 0., 0., 0.])}"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "mydict = {'x': x, 'y': y}\n",
        "torch.save(mydict, 'mydict')\n",
        "mydict2 = torch.load('mydict')\n",
        "mydict2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biblical-pharmaceutical"
      },
      "source": [
        "## **5.2 Loading and Saving Model Parameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "injured-finland"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.hidden = nn.Linear(20, 256)\n",
        "        self.output = nn.Linear(256, 10)\n",
        "    def forward(self, x):\n",
        "        return self.output(F.relu(self.hidden(x)))\n",
        "    \n",
        "net = MLP()\n",
        "X = torch.randn(size=(2, 20))\n",
        "Y = net(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "random-clone"
      },
      "outputs": [],
      "source": [
        "torch.save(net.state_dict(), 'mlp.params')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "remarkable-scottish",
        "outputId": "0ebb38cf-048b-4de1-b894-b3c74cc412ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (hidden): Linear(in_features=20, out_features=256, bias=True)\n",
              "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "clone = MLP()\n",
        "clone.load_state_dict(torch.load('mlp.params'))\n",
        "clone.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "selected-manufacturer",
        "outputId": "eaed9c43-df5e-4fc5-bfd1-6c8b358cb205",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True, True, True, True, True]])"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ],
      "source": [
        "Y_clone = clone(X)\n",
        "Y_clone == Y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "digital-spokesman"
      },
      "source": [
        "# **6. GPUs**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stunning-smell"
      },
      "source": [
        "## **6.1 Computing Devices**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "diverse-smoke",
        "outputId": "44c779f0-55df-46e1-b714-19e2f506ae93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(device(type='cpu'), device(type='cuda'))"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ],
      "source": [
        "torch.device('cpu'), torch.device('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "surprised-offering",
        "outputId": "d7c5be4c-663d-41fa-ad0d-597d881cadce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ],
      "source": [
        "torch.cuda.device_count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "practical-trainer",
        "outputId": "a320a545-8e96-42ec-9b26-01ef056939ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(device(type='cuda', index=0),\n",
              " device(type='cpu'),\n",
              " [device(type='cuda', index=0)])"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ],
      "source": [
        "def try_gpu(i=0):\n",
        "    \"\"\"Return gpu(i) if exists, otherwise return cpu().\"\"\"\n",
        "    if torch.cuda.device_count() >= i + 1:\n",
        "        return torch.device(f'cuda:{i}')\n",
        "    return torch.device('cpu')\n",
        "\n",
        "def try_all_gpus():\n",
        "    \"\"\"Return all available GPUs, or [cpu(),] if no GPU exists.\"\"\"\n",
        "    devices = [torch.device(f'cuda:{i}')\n",
        "             for i in range(torch.cuda.device_count())]\n",
        "    return devices if devices else [torch.device('cpu')]\n",
        "\n",
        "try_gpu(), try_gpu(10), try_all_gpus()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "selected-wyoming"
      },
      "source": [
        "## **6.2 Tensors and GPUs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "scientific-planner",
        "outputId": "0d25aa4c-4dec-44d5-8368-4fba082f7714",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ],
      "source": [
        "x = torch.tensor([1, 2, 3])\n",
        "x.device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "secret-silicon",
        "outputId": "cd742296-c055-4b9e-e5ed-b2e20fe20aac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ],
      "source": [
        "X = torch.ones(2, 3, device=try_gpu())\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "imperial-carpet",
        "outputId": "1189de29-8d82-4118-c929-a501f7e8d05b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7180, 0.2979, 0.2464],\n",
              "        [0.2757, 0.1571, 0.9068]])"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ],
      "source": [
        "Y = torch.rand(2, 3, device=try_gpu(1))\n",
        "Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "thick-range",
        "outputId": "23cf9e26-588f-4327-bb62-0cec34b6e87f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]], device='cuda:0')\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "Z = X # Z = X.cuda(1)\n",
        "print(X)\n",
        "print(Z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "ecological-cursor"
      },
      "outputs": [],
      "source": [
        "net = nn.Sequential(nn.Linear(3, 1))\n",
        "net = net.to(device=try_gpu())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "residential-immune",
        "outputId": "e3471e0b-5671-40da-ac2a-ad83979972a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.6824],\n",
              "        [0.6824]], device='cuda:0', grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ],
      "source": [
        "net(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "periodic-carry",
        "outputId": "aed9d999-9a9f-4371-be05-2c05c3d3925a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ],
      "source": [
        "net[0].weight.data.device"
      ]
    }
  ]
}